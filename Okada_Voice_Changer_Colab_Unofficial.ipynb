{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freyzamarshall02/w-okadavoicechangercolab/blob/main/Okada_Voice_Changer_Colab_Unofficial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnR6lSmXBCN"
      },
      "source": [
        "<h1 style=\"text-align: center;\">\n",
        "  <span style=\"color: #00ffff;\">OKADA VOICE CHANGER COLAB (UNOFFICIAL)</span>\n",
        "</h1>\n",
        "\n",
        "<hr />\n",
        "  <h2 style=\"text-align: center;\">\n",
        "\n",
        "  <h2 style=\"text-align: center;\">\n",
        "    <span style=\"color: #FFFFFF;\">AI Realtime Voice Changer On Google Colab</span>\n",
        "\n",
        "   <h2 style=\"text-align: center;\">\n",
        "    <span style=\"color: #FFFFFF;\">Notebook By FreyzaMarshall</span>\n",
        "\n",
        "  </h2>\n",
        "  </span>\n",
        "  </h2>\n",
        "  <a href=\"https://ko-fi.com/freyzamarshall\" target=\"_parent\"><img src=\"https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&logo=ko-fi&logoColor=white\" align=\"right\" alt=\"Open\"></a>\n",
        "\n",
        "   <a href=\"https://discord.gg/sr5kyhRy3x\" target=\"_parent\"><img src=\"https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white\" align=\"right\" alt=\"Open\"></a>\n",
        "\n",
        "  <a href=\"https://www.youtube.com/@FreyzaMarshall_\" target=\"_parent\"><img src=\"https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white\" align=\"right\" alt=\"Open\"></a>\n",
        "\n",
        "\n",
        "For mobile user may experience bugs and feature limitations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Cell[1]** Installation\n",
        "\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.**\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **[Optional]** Connect to Google Drive\n",
        "#@markdown\n",
        "#@markdown Using Google Drive can improve load times a bit and your models will be stored, so you don't need to re-upload every time that you use.\n",
        "Use_Drive=False #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import codecs\n",
        "import time\n",
        "import threading\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def run_timer_with_tqdm(duration=420):\n",
        "    with tqdm(total=duration, desc='Estimate', bar_format='{l_bar}{bar}| {remaining}') as pbar:\n",
        "        for _ in range(duration):\n",
        "            time.sleep(1)\n",
        "            pbar.update(1)\n",
        "\n",
        "threading.Thread(target=run_timer_with_tqdm, args=(360,), daemon=True).start()\n",
        "\n",
        "# Configs\n",
        "current_version_hash = None\n",
        "latest_version_hash = None\n",
        "Run_Cell = 0\n",
        "notebook_env = 0\n",
        "\n",
        "# Check what platform the notebook is running on\n",
        "if not os.path.exists('/kaggle/working') and not os.path.exists('/content'):\n",
        "  notebook_env=3\n",
        "  print(\"Welcome to ColabMod\")\n",
        "elif os.path.exists('/kaggle/working'):\n",
        "  notebook_env=2\n",
        "  print(\"Welcome to Kaggle\")\n",
        "else:\n",
        "  notebook_env=1\n",
        "  print(\"Welcome to ColabMod\")\n",
        "  from google.colab import drive\n",
        "\n",
        "externalgit = codecs.decode('uggcf://tvguho.pbz/serlmnznefunyy02/ibvpr-punatre', 'rot_13')\n",
        "rvctimer = codecs.decode('uggcf://tvguho.pbz/uvanoy/eipgvzre.tvg', 'rot_13')\n",
        "pathloc = codecs.decode('ibvpr-punatre', 'rot_13')\n",
        "execution = requests.get(\"https://pastebin.com/raw/GUKvmk3F\").text\n",
        "\n",
        "print('\\033[36m\\033[1m\\033[3mCloning the repository...\\033[0m')\n",
        "\n",
        "subprocess.run(['git', 'clone', '--depth', '1', externalgit], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# Did you use Drive?\n",
        "if notebook_env==1:\n",
        "  if Use_Drive==True:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "      drive.mount('/content/drive')\n",
        "\n",
        "      !mkdir -p /content/drive/MyDrive/voice-changer/server/model_dir\n",
        "      !rm -rf /content/voice-changer/server/model_dir\n",
        "\n",
        "      drive_dir = \"/content/drive/MyDrive/voice-changer/server/model_dir\"\n",
        "      colab_dir = \"/content/voice-changer/server/model_dir\"\n",
        "      time.sleep(5)\n",
        "\n",
        "      os.symlink(drive_dir,colab_dir,True)\n",
        "%cd $pathloc/server/\n",
        "\n",
        "# Define the URL and the destination paths\n",
        "os.chdir('/content')\n",
        "url = 'https://huggingface.co/freyza/model_example/resolve/main/model_example.zip'\n",
        "zip_path = \"/content/model_example.zip\"\n",
        "extract_path = f\"{pathloc}/server\"\n",
        "\n",
        "# Download the zip file\n",
        "subprocess.run(['wget', '-q', '-O', zip_path, url], check=True)\n",
        "\n",
        "# Unzip the downloaded file to the specified directory\n",
        "subprocess.run(['unzip', '-o', '-q', zip_path, '-d', extract_path], check=True)\n",
        "\n",
        "# Remove the zip file after extraction\n",
        "subprocess.run(['rm', zip_path], check=True)\n",
        "\n",
        "# List the contents to verify\n",
        "subprocess.run(['ls', extract_path], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "os.chdir(f\"{pathloc}/server/\")\n",
        "print('\\033[36m\\033[1m\\033[3mSuccessfully cloned the repository!\\033[0m')\n",
        "\n",
        "# Custom sub\n",
        "version_file = '../client/demo/dist/assets/gui_settings/version.txt'\n",
        "if notebook_env == 1:\n",
        "    subprocess.run(['sed', '-i', \"s/-.-.-.-/Colab.Mod/\", version_file])\n",
        "elif notebook_env == 2:\n",
        "    subprocess.run(['sed', '-i', \"s/-.-.-.-/Kaggle.Mod/\", version_file])\n",
        "elif notebook_env == 3:\n",
        "    subprocess.run(['sed', '-i', \"s/-.-.-.-/Online.Mod/\", version_file])\n",
        "else:\n",
        "    subprocess.run(['sed', '-i', \"s/-.-.-.-/Online.Mod/\", version_file])\n",
        "    print(\"Notebook Env Not Found\")\n",
        "\n",
        "print('\\033[36m\\033[1m\\033[3mInstalling libportaudio2...\\033[0m')\n",
        "subprocess.run(['apt-get', '-y', 'install', '-qq', 'libportaudio2'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['sudo', 'apt-get', '-qq', 'update'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['sudo', 'apt-get', 'install', '-qq', 'portaudio19-dev', '-y'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "print('\\033[36m\\033[1m\\033[3mInstalling dependencies...(May take longer than estimated bcs i update the dependecies)\\033[0m')\n",
        "subprocess.run(['pip', 'install', 'uv'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['uv', 'venv', '.venv'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['uv', 'pip', 'install', '-r', 'requirements.txt', '--upgrade'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "mainpy = codecs.decode('ZZIPFreireFVB.cl', 'rot_13')\n",
        "mainname = codecs.decode('ZZIPFreireFVB', 'rot_13')\n",
        "os.rename(mainpy, \"HVoice.py\")\n",
        "subprocess.run(['sed', '-i', \"s/MMVCServerSIO/HVoice/\", \"HVoice.py\"])\n",
        "\n",
        "# Webstuff\n",
        "import asyncio\n",
        "import re\n",
        "subprocess.run(['pip', 'install', 'gdown', 'pyngrok'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "Run_Cell = 1\n",
        "clear_output()\n",
        "exec(execution)\n",
        "print('\\033[32m\\033[1m\\033[3mCell 1 Was Executed Completely\\033[0m')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3Lu-r3n6c3dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=======================Updated=========================\n",
        "import codecs\n",
        "import json\n",
        "import subprocess, threading, time, socket, urllib.request, portpicker, json\n",
        "from IPython.display import clear_output, Javascript\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# @title **Cell[2]** Start Server using **NGROK** or **HRZN**\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (~1-2 minutes)\n",
        "\n",
        "#======================Tunnels===========================\n",
        "\n",
        "TUNNEL = \"NGROK\" #@param [\"NGROK\",\"HRZN\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown You'll need a NGROK or HRZN account, but <font color=green>**it's free**</font> and easy to create!\n",
        "# @markdown ---\n",
        "# @markdown **1** - Create a <font color=green>**free**</font> account at [ngrok](https://dashboard.ngrok.com/signup) / [hrzn](https://hrzn.run/login) or **login with Google/Github account**\\\n",
        "# @markdown **2** - If you didn't logged in with Google/Github, you will need to **verify your e-mail**!\\\n",
        "# @markdown **3** - Get your [ngrok](https://dashboard.ngrok.com/get-started/your-authtoken) or [hrzn](https://hrzn.run/dashboard) to get your auth token, and place it here:\n",
        "Token = '' # @param {type:\"string\"}\n",
        "# @markdown **4** - *(OPTIONAL FOR NGROK)* Change to a region near to you\\\n",
        "# @markdown `Default Region: ap - Asia/Pacific (Singapore)`\n",
        "Region = \"ap - Asia/Pacific (Singapore)\" # @param [\"ap - Asia/Pacific (Singapore)\", \"au - Australia (Sydney)\",\"eu - Europe (Frankfurt)\", \"in - India (Mumbai)\",\"jp - Japan (Tokyo)\",\"sa - South America (Sao Paulo)\", \"us - United States (Ohio)\"]\n",
        "\n",
        "#@markdown **5** - *(optional)* Other options:\n",
        "ClearConsole = False  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Check if Run_Cell\n",
        "PORT = portpicker.pick_unused_port()\n",
        "if 'Run_Cell' not in globals():\n",
        "    print(\"No, Go back to the first cell and run it\")\n",
        "else:\n",
        "    if Run_Cell == 0:\n",
        "        print(\"No, Go back to the first cell and run it\")\n",
        "    else:\n",
        "        if TUNNEL == \"NGROK\":\n",
        "            from pyngrok import conf, ngrok\n",
        "            MyConfig = conf.PyngrokConfig()\n",
        "            MyConfig.auth_token = Token\n",
        "            MyConfig.region = Region[0:2]\n",
        "            conf.set_default(MyConfig)\n",
        "            ngrokConnection = ngrok.connect(PORT)\n",
        "            public_url = ngrokConnection.public_url\n",
        "        elif TUNNEL == \"HRZN\":\n",
        "            subprocess.run(['rm', '-rf', 'url.txt'])\n",
        "            subprocess.run(['hrzn', 'login', Token])\n",
        "            os.system(f\"hrzn tunnel http://localhost:{PORT} >> url.txt 2>&1 &\")\n",
        "            time.sleep(5)\n",
        "\n",
        "            with open('url.txt', 'r') as file:\n",
        "                public_url = subprocess.getoutput(\"grep -oE 'https://[a-zA-Z0-9.-]+\\\\.hrzn\\\\.run' url.txt\").strip()\n",
        "\n",
        "        def wait_for_server():\n",
        "            while True:\n",
        "                time.sleep(0.5)\n",
        "                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "                result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "                if result == 0:\n",
        "                    break\n",
        "                sock.close()\n",
        "            if ClearConsole:\n",
        "                clear_output()\n",
        "            print(\"--------- SERVER READY! ---------\")\n",
        "            print(\"Your server is available at:\")\n",
        "            print(public_url)\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "        threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "\n",
        "        !source .venv/bin/activate\n",
        "        subprocess.run(f\"python HVoice.py \"\n",
        "                       f\"-p {PORT} \"\n",
        "                       \"--https False \"\n",
        "                       \"--content_vec_500 pretrain/checkpoint_best_legacy_500.pt \"\n",
        "                       \"--content_vec_500_onnx pretrain/content_vec_500.onnx \"\n",
        "                       \"--content_vec_500_onnx_on false \"\n",
        "                       \"--hubert_base pretrain/hubert_base.pt \"\n",
        "                       \"--hubert_base_jp pretrain/rinna_hubert_base_jp.pt \"\n",
        "                       \"--hubert_soft pretrain/hubert/hubert-soft-0d54a1f4.pt \"\n",
        "                       \"--nsf_hifigan pretrain/nsf_hifigan/model \"\n",
        "                       \"--crepe_onnx_full pretrain/crepe_onnx_full.onnx \"\n",
        "                       \"--crepe_onnx_tiny pretrain/crepe_onnx_tiny.onnx \"\n",
        "                       \"--rmvpe pretrain/rmvpe.pt \"\n",
        "                       \"--model_dir model_dir \"\n",
        "                       \"--samples samples.json \"\n",
        "                       f\"--allowed-origins {public_url}\", shell=True)\n",
        "\n",
        "        if TUNNEL == \"NGROK\":\n",
        "            ngrok.disconnect(ngrokConnection.public_url)\n",
        "            clear_output()\n",
        "            print(\"--------- SERVER STOPPED! ---------\")\n",
        "        elif TUNNEL == \"HRZN\":\n",
        "            subprocess.run(['rm', '-rf', 'url.txt'])\n",
        "            subprocess.run(['fuser', '-k', str(PORT)])\n",
        "            clear_output()\n",
        "            print(\"--------- SERVER STOPPED! ---------\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-uS0hHeXc6EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "import codecs\n",
        "import importlib.util\n",
        "\n",
        "# Check if onnxruntime is installed\n",
        "onnx_installed = importlib.util.find_spec(\"onnxruntime\") is not None\n",
        "\n",
        "if not onnx_installed:\n",
        "    print(\"Installing onnxruntime...\")\n",
        "    !pip install onnxruntime -q\n",
        "    clear_output()\n",
        "    print(\"onnxruntime installed successfully.\")\n",
        "\n",
        "\n",
        "#@title **[Optional Cell]** Upload a voice model (Run this before running the Voice Changer)\n",
        "#@markdown Find your model here [voice-models](https://voice-models.com/)\n",
        "# @markdown ---\n",
        "model_slot = \"4\" #@param ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199']\n",
        "\n",
        "!rm -rf model_dir/$model_slot\n",
        "#@markdown **[Optional]** Add an icon to the model (Kosongin aja gapapa / It's okay to leave it blank)\n",
        "icon_link = \"\"  #@param {type:\"string\"}\n",
        "icon_link = '\"'+icon_link+'\"'\n",
        "!mkdir model_dir\n",
        "!mkdir model_dir/$model_slot\n",
        "#@markdown Put your model's download link here `(must be a zip file and don't use GPT-SoVITS Model)` only supports **huggingface.co** & **google drive**<br>\n",
        "model_link = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "if model_link.startswith(\"https://www.weights.gg\") or model_link.startswith(\"https://weights.gg\"):\n",
        "    print(\"Links from weights.gg is no longer supported.\")\n",
        "    sys.exit()\n",
        "elif model_link.startswith(\"https://drive.google.com\"):\n",
        "    model_link = '\"'+model_link+'\"'\n",
        "    !gdown $model_link --fuzzy -O model.zip\n",
        "    print(\"Model from Drive\")\n",
        "elif model_link.startswith(\"https://huggingface.co\"):\n",
        "    model_link = model_link\n",
        "    model_link = '\"'+model_link+'\"'\n",
        "    !curl -L $model_link > model.zip\n",
        "    print(\"Model from huggingface Link\")\n",
        "else:\n",
        "    model_link = model_link\n",
        "    model_link = '\"'+model_link+'\"'\n",
        "    !curl -L -O $model_link\n",
        "    !mv ./*.pth model_dir/$model_slot/\n",
        "    print('Model(.pth) or a direct model link.')\n",
        "\n",
        "# Conditionally set the iconFile based on whether icon_link is empty\n",
        "if icon_link == '\"\"':\n",
        "    iconFile = \"\"\n",
        "    print(\"icon_link is empty, so no icon file will be downloaded.\")\n",
        "else:\n",
        "    iconFile = \"icon.png\"\n",
        "    !curl -L $icon_link > model_dir/$model_slot/icon.png\n",
        "\n",
        "!unzip model.zip -d model_dir/$model_slot\n",
        "\n",
        "!mv model_dir/$model_slot/*/* model_dir/$model_slot/\n",
        "!rm -rf model_dir/$model_slot/*/\n",
        "!rm -rf model.zip\n",
        "#@markdown **Model Voice Conversion Setting**\n",
        "Tune = 0  #@param {type:\"slider\",min:-24,max:24,step:1}\n",
        "Index = 0  #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "\n",
        "param_link = \"\"\n",
        "if param_link == \"\":\n",
        "    paramset = requests.get(\"https://pastebin.com/raw/DuznQ4Fg\").text\n",
        "    exec(paramset)\n",
        "\n",
        "clear_output()\n",
        "print(\"\\033[93mModel with the name of \"+model_name+\" has been Imported to slot \"+model_slot)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4osXm1IRc9-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}